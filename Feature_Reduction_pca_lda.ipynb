{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature_Reduction_pca_lda.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN0kJzP0Zz7Fjcb6liFps7g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vikaspandeyds/DataScience/blob/master/Feature_Reduction_pca_lda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lef_XIXsDy1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd, numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEw81QefECbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########PCA\n",
        "from sklearn.decomposition import PCA\n",
        "# Make an instance of the Model\n",
        "pca = PCA(.98,random_state=1)\n",
        "pca.fit(X)\n",
        "X = pca.transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4izZXbLSSRM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = pd.DataFrame(data = X, columns = ['principal component 1', 'principal component 2'])\n",
        "y=pd.DataFrame(data=y,columns=['target'])\n",
        "Df = pd.concat([X, y[['target']]], axis = 1)\n",
        "Df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At6ZeuhYE4-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca.score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VjURnLWE7LW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca.explained_variance_ratio_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g1Q2uDCFlwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########LDA\n",
        "# Load libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "# Load the Iris flower dataset:\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "lda = LinearDiscriminantAnalysis(n_components=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1JvDI_SFxh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run an LDA and use it to transform the features\n",
        "X_lda = lda.fit(X, y).transform(X)\n",
        "# Print the number of features\n",
        "print('Original number of features:', X.shape[1])\n",
        "print('Reduced number of features:', X_lda.shape[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia1vEvQmF8RB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda_var_ratios=lda.explained_variance_ratio_\n",
        "lda_var_ratios"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHg21AOuKAvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################\n",
        "# Create a function\n",
        "def select_n_components(var_ratio, goal_var: float) -> int:\n",
        "    # Set initial variance explained so far\n",
        "    total_variance = 0.0\n",
        "    \n",
        "    # Set initial number of features\n",
        "    n_components = 0\n",
        "    \n",
        "    # For the explained variance of each feature:\n",
        "    for explained_variance in var_ratio:\n",
        "        \n",
        "        # Add the explained variance to the total\n",
        "        total_variance += explained_variance\n",
        "        \n",
        "        # Add one to the number of components\n",
        "        n_components += 1\n",
        "        \n",
        "        # If we reach our goal level of explained variance\n",
        "        if total_variance >= goal_var:\n",
        "            # End the loop\n",
        "            break\n",
        "            \n",
        "    # Return the number of components\n",
        "    return n_components\n",
        "\n",
        "#################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRnEhn0DKEWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "select_n_components(lda_var_ratios, .98)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PH0mQS9O1BU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# k-means determine k\n",
        "distortions = []\n",
        "K = range(1,8)\n",
        "for k in K:\n",
        "    kmeanModel = KMeans(n_clusters=k)\n",
        "    kmeanModel.fit(X)\n",
        "    distortions.append(kmeanModel.inertia_)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGUGjS6lO6jd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "# Plot the elbow\n",
        "plt.plot(K, distortions, 'bx-')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Distortion')\n",
        "plt.title('The Elbow Method showing the optimal k')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oEVNhK3O91z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " kmeanModel = KMeans(n_clusters=3)\n",
        "X=pd.DataFrame(X)\n",
        "kmeanModel.fit(X)\n",
        "import pandas \n",
        "predict = kmeanModel.predict(X)\n",
        "X['cluster'] = predict\n",
        "pandas.plotting.parallel_coordinates(X, 'cluster',color=('#556270', '#4ECDC4', '#C7F464'))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMNcy1ziVm5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y67_BD9RgsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "X=Df\n",
        "\n",
        "kmeans = KMeans(n_clusters = 3, init = 'k-means++', random_state = 42)\n",
        "y_kmeans = kmeans.fit_predict(X)\n",
        "\n",
        "# Visualising the clusters\n",
        "plt.scatter(X.iloc[y_kmeans == 0, 0], X.iloc[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\n",
        "plt.scatter(X.iloc[y_kmeans == 1, 0], X.iloc[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\n",
        "plt.scatter(X.iloc[y_kmeans == 2, 0], X.iloc[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\n",
        "#plt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\n",
        "#plt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\n",
        "#plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s = 300, c = 'yellow', label = 'Centroids')\n",
        "plt.title('Clusters of customers')\n",
        "plt.xlabel('Annual Income (k$)')\n",
        "plt.ylabel('Spending Score (1-100)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lobIsYhmWeWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using the dendrogram to find the optimal number of clusters\n",
        "import scipy.cluster.hierarchy as sch\n",
        "dendrogram = sch.dendrogram(sch.linkage(Df, method = 'ward'))\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Customers')\n",
        "plt.ylabel('Euclidean distances')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4rATDdLWhNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fitting Hierarchical Clustering to the dataset\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "hc = AgglomerativeClustering(n_clusters = 2, affinity = 'euclidean', linkage = 'ward')\n",
        "y_hc = hc.fit_predict(X)\n",
        "y_hc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-FXsUf0XZjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Df.iloc[y_hc == 1,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv0gw1xLWkJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Visualising the clusters\n",
        "plt.scatter(Df.iloc[y_hc == 0, 0], Df.iloc[y_hc == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\n",
        "plt.scatter(Df.iloc[y_hc == 1, 0], Df.iloc[y_hc == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\n",
        "#plt.scatter(X[y_hc == 2, 0], X[y_hc == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\n",
        "#plt.scatter(X[y_hc == 3, 0], X[y_hc == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\n",
        "#plt.scatter(X[y_hc == 4, 0], X[y_hc == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\n",
        "plt.title('Clusters of customers')\n",
        "plt.xlabel('Annual Income (k$)')\n",
        "plt.ylabel('Spending Score (1-100)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvZeZaK4XRlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "outlier_detection = DBSCAN(eps = .2,  metric='euclidean',  min_samples = 2, n_jobs = -1)\n",
        "clusters = outlier_detection.fit_predict(Df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EW5YQyAtbY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outlier_detection.labels_\n",
        "df1=Df.iloc[outlier_detection.labels_==-1,:]\n",
        "df1.count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N6prmk2Z3jV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(6,5))\n",
        "ax.scatter(Df.iloc[outlier_detection.labels_==-1,0], Df.iloc[outlier_detection.labels_==-1,1], c=outlier_detection.labels_,cmap=cmap, colorbar = False)\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT401tKPZ3v-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "labels_true=y\n",
        "# Compute DBSCAN\n",
        "db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
        "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
        "core_samples_mask[db.core_sample_indices_] = True\n",
        "labels = db.labels_\n",
        "\n",
        "# Number of clusters in labels, ignoring noise if present.\n",
        "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "n_noise_ = list(labels).count(-1)\n",
        "\n",
        "print('Estimated number of clusters: %d' % n_clusters_)\n",
        "print('Estimated number of noise points: %d' % n_noise_)\n",
        "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
        "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
        "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
        "print(\"Adjusted Rand Index: %0.3f\"\n",
        "      % metrics.adjusted_rand_score(labels_true, labels))\n",
        "print(\"Adjusted Mutual Information: %0.3f\"\n",
        "      % metrics.adjusted_mutual_info_score(labels_true, labels))\n",
        "print(\"Silhouette Coefficient: %0.3f\"\n",
        "      % metrics.silhouette_score(X, labels))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOcka6OZf7aD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot result\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Black removed and is used for noise instead.\n",
        "unique_labels = set(labels)\n",
        "colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
        "for k, col in zip(unique_labels, colors):\n",
        "    if k == -1:\n",
        "        # Black used for noise.\n",
        "        col = [0, 0, 0, 1]\n",
        "\n",
        "    class_member_mask = (labels == k)\n",
        "\n",
        "    xy = X.iloc[class_member_mask & core_samples_mask]\n",
        "    plt.plot(xy.iloc[:, 0], xy.iloc[:, 1], 'o', markerfacecolor=tuple(col),markeredgecolor='k', markersize=14)\n",
        "\n",
        "    xy = X.iloc[class_member_mask & ~core_samples_mask]\n",
        "    plt.plot(xy.iloc[:, 0], xy.iloc[:, 1], 'o', markerfacecolor=tuple(col),markeredgecolor='k', markersize=6)\n",
        "\n",
        "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}